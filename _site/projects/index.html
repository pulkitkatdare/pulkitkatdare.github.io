

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Projects - Home</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Home">
<meta property="og:title" content="Projects">


  <link rel="canonical" href="https://Shuijing725.github.io//projects/">
  <meta property="og:url" content="https://Shuijing725.github.io//projects/">







  

  












  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Pulkit Katdare",
      "url" : "https://Shuijing725.github.io/",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="https://Shuijing725.github.io//feed.xml" type="application/atom+xml" rel="alternate" title="Home Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="https://Shuijing725.github.io//assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="https://Shuijing725.github.io//images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="https://Shuijing725.github.io//images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="https://Shuijing725.github.io//images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="https://Shuijing725.github.io//images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="https://Shuijing725.github.io//images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="https://Shuijing725.github.io//images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="https://Shuijing725.github.io//images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="https://Shuijing725.github.io//images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="https://Shuijing725.github.io//images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="https://Shuijing725.github.io//images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="https://Shuijing725.github.io//images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="https://Shuijing725.github.io//images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="https://Shuijing725.github.io//images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="https://Shuijing725.github.io//images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="https://Shuijing725.github.io//images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="https://Shuijing725.github.io//images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="https://Shuijing725.github.io//images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="https://Shuijing725.github.io//assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="https://Shuijing725.github.io//">Home</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://Shuijing725.github.io//publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://Shuijing725.github.io//projects/">Projects</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://Shuijing725.github.io//teaching/">Services</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://Shuijing725.github.io//cv/">CV</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://Shuijing725.github.io//slides/">Slides</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://Shuijing725.github.io//portfolio/">Portfolio</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    



<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="https://Shuijing725.github.io//images/profile.png" class="author__avatar" alt="">
    
  </div>

  <div class="author__content">
    <h3 class="author__name"></h3>
    <p class="author__bio">blah blah blah</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
      
      
      
        <li><a href="mailto:katdare2@illinois.edu"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> katdare2@illinois.edu</a></li>
      
      
       
      
      
      
      
        <li><a href="https://www.linkedin.com/in/pulkit-katdare-08087b96"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
      
      
      
      
      
      
        <li><a href="https://github.com/pulkitkatdare"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=yC1tsz8AAAAJ&hl=en"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <div class="archive">
    
      <h1 class="page__title">Projects</h1>
    
    <h2 id="robot-crowd-navigation">Robot Crowd Navigation</h2>

<h3 id="intention-aware-robot-crowd-navigation-with-attention-based-interaction-graph">Intention Aware Robot Crowd Navigation with Attention-Based Interaction Graph</h3>
<p>We study the problem of safe and intention-aware robot navigation in dense and interactive crowds. 
Most previous reinforcement learning (RL) based methods fail to consider different types of interactions among all agents or ignore the intentions of people, which results in performance degradation. 
We propose a novel recurrent graph neural network with attention mechanisms to capture heterogeneous interactions among agents through space and time. 
To encourage longsighted robot behaviors, we infer the intentions of dynamic agents by predicting their future trajectories for several timesteps. 
The predictions are incorporated into a model-free RL framework to prevent the robot from intruding into the intended paths of other agents. 
We demonstrate that our method enables the robot to achieve good navigation performance and non-invasiveness in challenging simulation and real-world scenarios.<br />
<a href="https://arxiv.org/abs/2203.01821">[Paper]</a> <a href="https://www.youtube.com/watch?v=p_asv42Kl8Q">[Video]</a> <a href="https://sites.google.com/view/intention-aware-crowdnav/home">[Website]</a> <a href="https://github.com/Shuijing725/CrowdNav_Prediction_AttnGraph">[Code]</a></p>

<p><img src="/images/socialZone.png" width="450" /></p>

<h3 id="decentralized-structural-rnn-for-robot-crowd-navigation-with-deep-reinforcement-learning">Decentralized Structural-RNN for Robot Crowd Navigation with Deep Reinforcement Learning</h3>
<p>Safe and efficient navigation through human crowds is an essential capability for mobile robots. 
We propose decentralized structural-Recurrent Neural Network (DS-RNN), a novel network that reasons about spatial and temporal relationships for robot decision making in crowd navigation. 
We train our network with model-free deep reinforcement learning without any expert supervision. 
We demonstrate that our model outperforms previous methods and successfully transfer the policy learned in the simulator to a real-world TurtleBot 2i.<br />
<a href="https://arxiv.org/abs/2011.04820">[Paper]</a> <a href="https://sites.google.com/illinois.edu/crowdnav-dsrnn/home">[Website]</a> <a href="https://github.com/Shuijing725/CrowdNav_DSRNN">[Code]</a> <a href="https://youtu.be/bYO-1IAjzgY">[Video]</a></p>

<p><img src="/images/crowdnav.jpg" width="450" /></p>

<h3 id="occlusion-aware-crowd-navigation-using-people-as-sensors">Occlusion-Aware Crowd Navigation Using People as Sensors</h3>
<p>Occlusions are highly prevalent in crowded spaces due to a limited robot sensor range and obstructing human agents. 
We propose integrating such social inference techniques into the planning pipeline.
We use a variational autoencoder with a specially designed loss function to learn representations that are meaningful for occlusion inference. 
We develop a deep reinforcement learning algorithm that incorporates the learned representations for occlusion-aware path planning that simultaneously learns to avoid collision with both observed and occluded human agents.
We demonstrate that our occlusion-aware policy can estimate agents in occluded spaces and achieves comparable navigation performance to a navigation policy with omniscient, full map information. 
To the best of our knowledge, this work is the first to use social occlusion inference for crowd navigation. <br />
<a href="https://arxiv.org/abs/2210.00552">[Paper]</a> <a href="https://www.youtube.com/watch?v=BG5s7w5BdME">[Video]</a> <a href="https://github.com/yejimun/PaS_CrowdNav">[Code]</a> <a href="https://techxplore.com/news/2022-11-autonomous-mobile-robots-crowded-spaces.html">[Newspaper article]</a></p>

<p><img src="/images/pas_crowdnav.jpg" width="500" /></p>

<h2 id="autonomous-driving">Autonomous Driving</h2>

<h3 id="structural-attention-based-recurrent-variational-autoencoder-for-highway-vehicle-anomaly-detection">Structural Attention-Based Recurrent Variational Autoencoder for Highway Vehicle Anomaly Detection</h3>
<p>In autonomous driving, detection of abnormal driving behaviors is essential to ensure the safety of vehicle controllers.
We propose a novel unsupervised framework for highway anomaly detection named Structural Attention-based Recurrent VAE (SABeR-VAE), which explicitly uses the structure of the environment to aid anomaly identification. 
Specifically, we use a vehicle self-attention module to learn the relations among vehicles on a road, and a separate lane-vehicle attention module to model the importance of permissible lanes to aid in trajectory prediction. 
Conditioned on the attention modules’ outputs, a recurrent encoder-decoder architecture with a stochastic Koopman operator-propagated latent space predicts the next states of vehicles. 
Our model is trained end-to-end to minimize prediction loss on normal vehicle behaviors, and is deployed to detect anomalies in (ab)normal scenarios.
The results of our method show that modeling environmental factors is essential to detecting a diverse set of anomalies in deployment.<br />
<a href="https://arxiv.org/abs/2301.03634">[Paper]</a> <a href="https://sites.google.com/illinois.edu/saber-vae">[Website]</a> <a href="https://gitlab.engr.illinois.edu/hubris/highway-anomaly-detection">[Code]</a></p>

<p><img src="/images/lane_discretization.png" width="450" /></p>

<h3 id="learning-to-navigate-intersections-with-unsupervised-driver-trait-inference">Learning to Navigate Intersections with Unsupervised Driver Trait Inference</h3>
<p>Navigation through uncontrolled intersections is one of the key challenges for autonomous vehicles.
Identifying the subtle differences in hidden traits of other drivers can bring significant benefits when navigating in such environments.
We propose an unsupervised method for inferring driver traits such as driving styles from observed vehicle trajectories. 
Then, we use the inferred traits to improve the navigation of an autonomous vehicle through a T-intersection. 
Our pipeline enables the autonomous vehicle to adjust its actions when dealing with drivers of different traits to ensure safety and efficiency. <br />
<a href="https://arxiv.org/abs/2109.06783">[Paper]</a> <a href="https://sites.google.com/illinois.edu/vae-trait-inference/home">[Website]</a> <a href="https://github.com/Shuijing725/VAE_trait_inference">[Code]</a> <a href="https://www.youtube.com/watch?v=wqbgsjSvkAo&amp;t=1s">[Video]</a> <a href="https://www.youtube.com/watch?v=hfSlciB1jew&amp;t=29s">[Presentation]</a></p>

<p><img src="/images/trait_opening.png" width="450" /></p>

<h3 id="combining-model-based-controllers-and-generative-adversarial-imitation-learning-for-traffic-simulation">Combining Model-Based Controllers and Generative Adversarial Imitation Learning for Traffic Simulation</h3>
<p>An accurate model of human drivers is essential to validate the performance of autonomous vehicles in multiagent and interactive scenarios. Previous works on human driver modeling either use model-based controllers that are not adaptive and need laborious parameter-tuning or learn an end-to-end black box model that has few safety guarantees.
We propose a two-stage hybrid driver model, where a high-level neural network generates driver traits that are used as the parameters of the low-level model-based controllers for simulated drivers.
We train our model using generative adversarial imitation learning with reward augmentation and parameter sharing from real-world vehicle trajectory data. By combining data-driven and model-based approaches, our method simulates traffic agents with expressive, safe, and human-like behaviors.
We demonstrate that our method outperforms state-of-the-art baselines in terms of imitation performance and safety in a multi-agent highway driving scenario. <br />
<a href="https://ieeexplore.ieee.org/abstract/document/9922261">[Paper]</a></p>

<p><img src="/images/itsc.jpg" width="450" /></p>

<h2 id="instruction-following-robot">Instruction Following Robot</h2>

<h3 id="learning-visual-audio-representations-for-voice-controlled-robots">Learning Visual-Audio Representations for Voice-Controlled Robots</h3>
<p>Inspired by sensorimotor theory, we propose a novel pipeline for task-oriented voice-controlled robots. 
Previous method relies on a large amount of labels as well as task-specific reward functions. 
Not only can such an approach hardly be improved after the deployment, but also has limited generalization across robotic platforms and tasks. 
To address these problems, we learn a visual-audio representation (VAR) that associates images and sound commands with minimal supervision. 
Using this representation, we generate an intrinsic reward function to learn robot policies with reinforcement learning, which eliminates the laborious reward engineering process. 
We demonstrate our approach on various robotic platforms, where the robots hear an audio command, identify the associated target object, and perform precise control to fulfill the sound command.
We also demonstrate that our VAR and the intrinsic reward function allows the robot to improve itself using only a small amount of labeled data collected in the real world. <br />
<a href="https://arxiv.org/abs/2109.02823">[Paper]</a></p>

<p><img src="/images/opening_iTHOR.png" width="450" /></p>

<h3 id="robot-sound-interpretation-combining-sight-and-sound-in-learning-based-control">Robot Sound Interpretation: Combining Sight and Sound in Learning-Based Control</h3>
<p>We explore the interpretation of sound for robot decision-making, inspired by human speech comprehension.
While previous methods use natural language processing to translate sound to text, we propose an end-to-end
deep neural network which directly learns control polices from images and sound signals.<br />
<a href="https://arxiv.org/abs/1909.09172">[Paper]</a> <a href="https://sites.google.com/site/changpeixin/home/Research/robot_sound_interpretation">[Website]</a> <a href="https://www.youtube.com/watch?v=0ONGQwhGn_Y">[Video]</a></p>

<p><img src="/images/rsi_opening.png" width="600" /></p>

<h2 id="assistive-robotics">Assistive Robotics</h2>

<h3 id="wayfinding-assistance-robot-for-people-with-visual-impairments">Wayfinding Assistance Robot for People with Visual Impairments</h3>
<p>Recent studies find that independent navigation is especially difficult for people with visual impairments.
The currently available tools for wayfinding are fairly limited to white canes, guide dogs, etc.
Providing a robot guide that could facilitate wayfinding in a variety of environments would significantly improve the quality of life and, 
most importantly, the independence of people with vision impairments. 
Through this project, we will explore the feasibility of robot navigation for guidance and wayfinding. <br />
<a href="https://www.youtube.com/watch?v=BS9r5bkIass&amp;t=67s">[Video]</a></p>

<p><img src="/images/wayfinding.jpg" width="450" /></p>

<h2 id="computer-vision">Computer Vision</h2>

<h3 id="world-in-motion-geometry-based-video-prediction-with-visual-odometry-prediction-and-view-synthesis">World in Motion: Geometry-based Video Prediction with Visual Odometry Prediction and View Synthesis</h3>
<p>Video prediction has a wide range of applications in planning and control for robotics. 
However, previous do not account for camera motion and perform poorly in scenarios with moving cameras when they are deployed on autonomous vehicles and mobile robots. 
We propose a geometry-based prediction framework named World in Motion. 
Based on a sequence of observed frames, our method first predicts future camera poses and extracts the 3D geometry of the world, which are then jointly used to generate predicted future frames. 
Specifically, we train a recurrent visual odometry model conditioned on raw RGB images with ground truth pose labels.
Then, we train SynSin, a view synthesis method to generate 2D images from novel viewpoints using a 3D world representation. 
We demonstrate that our hierarchical deterministic approach outperforms previous stochastic works on the KITTI dataset.</p>

<p><img src="/images/world_in_motion.png" width="800" /></p>

<h3 id="prostate-cancer-diagnosis-by-deep-learning">Prostate Cancer Diagnosis by Deep Learning</h3>
<p>Prostate cancer diagnosis requires expensive equipments and experienced trained pathologists.
With recent advances in computer vision, we classify cancerous and healthy tissue biopsy images using ResNet. 
Then, we use ensemble methods to boost the performance of ResNet models and achieve nearly perfect testing performance on the US Biomax prostate cancer dataset. <br />
<a href="https://www.ideals.illinois.edu/handle/2142/100023">[Abstract]</a> <a href="/files/ECE499-Sp2018-liu-Shuijing.pdf">[Paper]</a> <a href="/files/senior_thesis_presentation.pdf">[Slides]</a></p>

<div class="imageContainer">
<img src="/images/cancer_diagnosis.png" width="1100" />
</div>

<h2 id="machine-learning">Machine Learning</h2>

<h3 id="robust-deep-reinforcement-learning-with-adversarial-attacks">Robust Deep Reinforcement Learning with Adversarial Attacks</h3>
<p>We propose adversarial attacks to perturb reinforcement learning algorithms (e.g. DQN, DDPG, etc), and then uses adversarial training to improve the robustness of these algorithms.
We found that our adversarial training significantly improves the robustness of RL algorithms to parameter variations in OpenAI Gym benchmarks.<br />
<a href="https://arxiv.org/abs/1712.03632">[Paper]</a> <a href="https://www.youtube.com/watch?v=8xPaca3cjEU">[Video]</a> <a href="/files/daslab_poster.pdf">[Poster]</a> <a href="https://shuijing725.github.io/files/Supplementary_for_Robust_Deep_Reinforcement_Learning_with_Adversarial_Attacks.pdf">[Supplementary materials]</a></p>

<h3 id="off-environment-evaluation-using-convex-risk-minimization">Off Environment Evaluation Using Convex Risk Minimization</h3>
<p>Applying reinforcement learning (RL) methods on robots typically involves training a policy in simulation and deploying it on a robot in the real world. 
However, model mismatch between the real world and the simulator causes RL agents to perform suboptimally.
To address this, we propose a convex risk minimization algorithm to estimate the model mismatch between the simulator and the target domain. 
We show that this estimator can be used to evaluate performance of RL agents in the target domain, effectively bridging the gap between simulation and real world. 
Our experiments demonstrate that our method effectively evaluates performance of policies in OpenAI Gym environments and a real Kinova Gen3 arm.<br />
<a href="https://arxiv.org/abs/2112.11532">[Paper]</a> <a href="https://github.com/pulkitkatdare/offenveval">[Code]</a></p>

<h3 id="hierarchical-self-imitation-learning-for-single-agent-tasks-with-sparse-rewards">Hierarchical Self-Imitation Learning for Single-Agent Tasks with Sparse Rewards</h3>
<p>Reinforcement learning problems with sparse and delayed rewards are challenging to solve.
We propose a single agent reinforcement learning algorithm named HAC+GASIL that combines Generative Adversarial Self-Imitation Learning (GASIL) and
Hierarchical Actor-Critic (HL).
HAC+GASIL divides the policy of an agent into multiple levels and the hierarchical policy can be trained end-to-end.
To evaluate HAC+GASIL, we perform experiments in OpenAI Multi-Agent Particle Environment with sparse and delayed reward stochastic scenarios. <br />
<a href="https://www.ideals.illinois.edu/handle/2142/110267">[Paper]</a></p>


  </div>
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<a href="/sitemap/">Sitemap</a>
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/pulkitkatdare"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="https://Shuijing725.github.io//feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 Pulkit Katdare. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="https://Shuijing725.github.io//assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

